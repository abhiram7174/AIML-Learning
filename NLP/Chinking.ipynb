{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "187319d7",
   "metadata": {},
   "source": [
    "#                                                 Chinking in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eb0868",
   "metadata": {},
   "source": [
    "<b>Chinking</b> is used together with chunking, but while <b>chunking</b> is used to include a pattern, <b>chinking</b> is used to exclude a pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed60bd7",
   "metadata": {},
   "source": [
    " One can even define a pattern or words that can’t be a part of chuck and such words are known as chinks. A **ChunkRule class** specifies what words or patterns to include and exclude in a chunk. Chinking is a lot like chunking, it is basically a way for you to remove a chunk from a chunk. The chunk that you remove from your chunk is your chink."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91af3066",
   "metadata": {},
   "source": [
    "Let’s reuse the quote you used in the section on chunking. You already have a list of tuples containing each of the words in the quote along with its part of speech tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b393df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence= \"It's a dangerous business, Frodo, going out your door.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d566ea",
   "metadata": {},
   "source": [
    "Now we tokenize the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4796989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e52e9390",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagger=word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fddf052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'dangerous',\n",
       " 'business',\n",
       " ',',\n",
       " 'Frodo',\n",
       " ',',\n",
       " 'going',\n",
       " 'out',\n",
       " 'your',\n",
       " 'door',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tagger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802060f7",
   "metadata": {},
   "source": [
    "Now we tagging the each  words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb6958f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lotr_pos_tags=nltk.pos_tag(pos_tagger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06495713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('dangerous', 'JJ'),\n",
       " ('business', 'NN'),\n",
       " (',', ','),\n",
       " ('Frodo', 'NNP'),\n",
       " (',', ','),\n",
       " ('going', 'VBG'),\n",
       " ('out', 'RP'),\n",
       " ('your', 'PRP$'),\n",
       " ('door', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lotr_pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7593167b",
   "metadata": {},
   "source": [
    "The next step is to create a grammar to determine what you want to **include and exclude in your chunks**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ad5d6",
   "metadata": {},
   "source": [
    "Before doing it you need to specify the rulz.  u’re going to use more than one line because you’re going to have more than one rule. Because you’re using more than one line for the grammar, you’ll be using **triple quotes (\"\"\"):**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ff179c4",
   "metadata": {},
   "outputs": [],
   "source": [
    " grammar = \"\"\"\n",
    "... Chunk: {<.*>+}\n",
    "...        }<JJ>{\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a8c91c",
   "metadata": {},
   "source": [
    "First Rule of grammer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdc5858",
   "metadata": {},
   "source": [
    "The first rule of your grammar is {<.*>+} . \n",
    "This rule has curly braces that face inward ({}) because it’s used to determine what patterns you want to include in you chunks. In this case, you want to include everything: <.*>+."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d554c1",
   "metadata": {},
   "source": [
    "Second rule"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cce62bb5",
   "metadata": {},
   "source": [
    "The second rule of your grammar is } \"<JJ>\" {. <ins>This rule has curly braces that face outward (}{) because it’s used to determine what patterns you want to exclude in your chunks.</ins> In this case, you want to exclude adjectives:<JJ>.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c4af6",
   "metadata": {},
   "source": [
    "Create a chunk parser with this grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "445b683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_parser = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c77787f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chunk.RegexpParser with 1 stages>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4992ccb1",
   "metadata": {},
   "source": [
    "Now chunk your sentence with the chink you specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6b76d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = chunk_parser.parse(lotr_pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c1ee21",
   "metadata": {},
   "source": [
    "The tree shows that adjective is excluded from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa9cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ce038",
   "metadata": {},
   "source": [
    "We excluded the adjective 'dangerous' from your chunks and are left with two chunks containing everything else. The first chunk has all the text that appeared before the adjective that was excluded. The second chunk contains everything after the adjective that was excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a797b0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
