{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "797be4ef",
   "metadata": {},
   "source": [
    "#                                           Chunking in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4748f0",
   "metadata": {},
   "source": [
    "<h>Chunking in NLP</h>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0569ac44",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>chunking</b> is the meaning full extraction of short phrases from the sentences (tagged with pos).<br>\n",
    "    <b>chunks</b> are made up of words and kind of theses words are defined using pos tag.\n",
    "</p>\n",
    "\n",
    "<b><ins>Working:</ins></b>\n",
    "<ul>\n",
    "         <li>it works on top of pos tagging</li>\n",
    "         <li>input: pos_tag, output:chunk</li>\n",
    "         <li>Note: Extract information from text such as location ,person and names.</li>\n",
    "</ul>\n",
    "</p> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6dc902",
   "metadata": {},
   "source": [
    "<b>Note:</b> A <b>phrase</b> is a word or group of words that works as a single unit to perform a grammatical function. <b>Noun phrases</b> are built around a noun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272063d4",
   "metadata": {},
   "source": [
    "<p>\n",
    "Here are some examples:\n",
    "<ul>\n",
    "<li>“A planet”</li>\n",
    "<li>“A tilting planet”</li>\n",
    "<li>“A swiftly tilting planet”</li>\n",
    "</ul>\n",
    "</p>\n",
    "Chunking makes use of <mark>POS tags</mark> to group words and apply chunk tags to those groups. Chunks don’t overlap, so one instance of a word can be in only one chunk at a time.\n",
    "\n",
    "Here’s how to import the relevant parts of NLTK in order to chunk:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30315ab",
   "metadata": {},
   "source": [
    "First step as we import nltk libaray for word tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c571791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d0795",
   "metadata": {},
   "source": [
    "Before you can chunk, you need to make sure that the parts of speech in your text are tagged, so create a string for POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7e513fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence= \"It's a dangerous business, Frodo, going out your door.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61ddc8",
   "metadata": {},
   "source": [
    "Now tokenize that string by word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e5b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_lotr_quote=word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ee6e8ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " \"'s\",\n",
       " 'a',\n",
       " 'dangerous',\n",
       " 'business',\n",
       " ',',\n",
       " 'Frodo',\n",
       " ',',\n",
       " 'going',\n",
       " 'out',\n",
       " 'your',\n",
       " 'door',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_lotr_quote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1b2051",
   "metadata": {},
   "source": [
    "Now you’ve got a list of all of the words in lotr_quote."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a484cfc",
   "metadata": {},
   "source": [
    "The next step is to tag those words by part of speech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "321fa874",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1438605",
   "metadata": {},
   "outputs": [],
   "source": [
    "lotr_pos_tags = nltk.pos_tag(words_in_lotr_quote)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bd14c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('dangerous', 'JJ'),\n",
       " ('business', 'NN'),\n",
       " (',', ','),\n",
       " ('Frodo', 'NNP'),\n",
       " (',', ','),\n",
       " ('going', 'VBG'),\n",
       " ('out', 'RP'),\n",
       " ('your', 'PRP$'),\n",
       " ('door', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lotr_pos_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17aa2df",
   "metadata": {},
   "source": [
    "You’ve got a list of tuples of all the words in the quote, along with their POS tag. In order to chunk, you first need to define a chunk grammar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dedfc9",
   "metadata": {},
   "source": [
    "<b>Note</b>: A chunk grammar is a combination of rules on how sentences should be chunked. It often uses <a href = \"https://realpython.com/regex-python/\">,regular expressions</a>  or <b>regexes</b>.\n",
    "\n",
    "For this tutorial, you don’t need to know how regular expressions work, but they will definitely come in handy for you in the future if you want to process text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84598a58",
   "metadata": {},
   "source": [
    "Create a chunk grammar with one regular expression rule:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea2baf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8107c8",
   "metadata": {},
   "source": [
    "<b>NP</b> stands for noun phrase. You can learn more about noun phrase chunking in <a href = \"https://www.nltk.org/book/ch07.html#noun-phrase-chunking\">, Chapter 7</a> of Natural Language Processing with Python—Analyzing Text with the Natural Language Toolkit.\n",
    "<p>\n",
    "According to the rule you created, your chunks:\n",
    "<ul>\n",
    "    <li>Start with an optional (?) determiner ('DT')</li>\n",
    "    <li>Can have any number (*) of adjectives (JJ)</li>\n",
    "    <li>End with a noun (&lt;NN>) </li>\n",
    "<ul>\n",
    "<p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfefc32",
   "metadata": {},
   "source": [
    "Create a chunk parser with this grammar:<br>\n",
    "Using this grammar, we create a chunk parser  and test it on our example sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a00f0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_parser = nltk.RegexpParser(grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214371eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chunk.RegexpParser with 1 stages>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52487006",
   "metadata": {},
   "source": [
    "Now try it out with your quote:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbd5c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = chunk_parser.parse(lotr_pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d0458",
   "metadata": {},
   "source": [
    "Now you can visual representation of tree showing phrases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21628fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec5440d",
   "metadata": {},
   "source": [
    "You got two noun phrases:\n",
    "\n",
    "1. **'a dangerous business'** has a determiner, an adjective, and a noun.\n",
    "2.**'door'** has just a noun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a88b6",
   "metadata": {},
   "source": [
    "Example problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "25bc9153",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=\"little yellow dog barked at cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d363fd7",
   "metadata": {},
   "source": [
    "Import necessary library for tokenization and pos_tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83829cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095fac7",
   "metadata": {},
   "source": [
    "Tokenize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f908e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_word= word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f38994e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['little', 'yellow', 'dog', 'barked', 'at', 'cat']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c91645",
   "metadata": {},
   "source": [
    "Finding out the pos _tag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6daa3c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_taged=nltk.pos_tag(token_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2247d728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('little', 'JJ'),\n",
       " ('yellow', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('barked', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('cat', 'NN')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_taged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41040c92",
   "metadata": {},
   "source": [
    "Then we specify the grammatic rule for phrases extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09b205f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Then we use chunck parser to extract text from our specified grammatic rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62f38d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunck_parser=nltk.RegexpParser(grammar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a59a15c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chunk.RegexpParser with 1 stages>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunck_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d3d4e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=chunck_parser.parse(pos_taged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b867c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae14bad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
